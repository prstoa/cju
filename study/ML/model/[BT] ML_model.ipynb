{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 선형회귀(linear regressor)\n",
    "$y=w1x1 + w2x2+b$\n",
    "- 종속 변수 y와 한 개 이상의 독립 변수 x와의 선형 상관 관계를 모델링하는 회귀분석 기법\n",
    "- 측정 방법으로 mse사용\n",
    "\n",
    "- 사용 코드<br>\n",
    "    from sklearn.linear_model import LinearRegression<br>\n",
    "    lr = LinearRegression(fit_intercept=Flase)  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # fit_intercept : 절편을 계산하지 않음<br>\n",
    "    lr.fit(X_train, y_train)<br>\n",
    "    lr.score(X_test, y_test)  # 결정계수 r^2 점수<br>\n",
    "    lr.predict(X_test)<br>\n",
    "    lr.coef_, lr.intercept_   # 가중치, 절편"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM(support vector machine)\n",
    "- 패턴 인식, 자료 분석을 위한 지도 학습 모델이며, 주로 분류와 회귀 분석을 위해 사용<br>\n",
    "- 딥러닝 이전 뛰어난 성능, 분류를 위한 기준 선(decision boundary)을 정의하는 모델(벡터 연산)<br>\n",
    "- 서포트 벡터 : 결정 경계에 가장 가까운 각 클래스의 점들이다.\n",
    "- 서포트 벡터를 사용해서 결정 경계를 정의하고, 분류되지 않은 점을 해당 결정 경계와 비교해서 분류<br>\n",
    "- margin(파라미터 c)<br>\n",
    "  : 서포트 벡터와 결정 경계 사이의 거리, 허용 가능한 오류 범위에서 최대 마진 찾음<br>\n",
    "  1) hard margin : outlier를 허용하지 않음(적합), 서포트 벡터와 결정 경계 거리가 좁음, 파라미터 c값이 클수록<br>\n",
    "  2) soft margin : outlier를 어느정도 허용(과소적합), 서포트 벡터와 거리가 멀어짐, , 파라미터 c값이 작을수록<br>\n",
    "- kernel<br>\n",
    "  : 비선형 분류를 하기 위해서 주어진 데이터를 고차원 특징 공간으로 사상하는 작업<br>\n",
    "  1) polynomial(다항식) : 3차원으로 변환<br>\n",
    "  2) Radial Bias Function(방사 기저 함수) > rbf 커널, 가우시안 커널 : 무한한 차원으로 변환<br>\n",
    "- gamma(rbf커널의 파라미터)\n",
    "  : 결정경계의 유연성(곡선), 값이 높을수록 구불구불 함(과적합)\n",
    "- 사용 코드<br>\n",
    "  from sklearn.svm import SVC<br>\n",
    "  svc=SVC(kernel = 'linear', c = 0.01, gamma = 0.5) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;# c : margin값, kernel : linear·poly·rbf, gamma : 결정 경계의 유연성<br>\n",
    "  svc.fit(x_train,y_train)<br>\n",
    "  svc.predict(x_test)<br>\n",
    "  svc.support_vectors_ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;# 결정 경계를 정의하는 서포트 벡터 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN(K-Nearest Neighbors)\n",
    "- 이미지 처리, 영상에서 글자 인식과 얼굴 인식, 영화나 음악, 상품 추천에 대한 개인별 선호 예측, 의료, 유전자 데이터의 패턴 인식 등에서 사용<br>\n",
    "- 기본 로직<br>\n",
    "  1) 새로운 샘플 가까운 거리에 있는 몇 가지 라벨을 함께 본다(유클리드 거리)<br>\n",
    "  2) 가장 빈도가 높은 것을 통해 분류한다(k갯수)<br>\n",
    "- 장점 : 단순하다, 수치 기반 데이터에서 성능이 좋다, 훈련 단계가 빠름<br>\n",
    "- 단점 : 적절한 k의 선택, 데이터가 많아지면 분류가 느려짐<br>\n",
    "- 거리기반이므로 스케일링(정규화) 필요<br>\n",
    "- 사용 코드<br>\n",
    "  from sklearn.neighbors import KNeighborsClassifier<br>\n",
    "  knn = KNeighborsClassifier(n_neighbors = 1) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;# n_neighbors : k의 갯수<br>\n",
    "  knn.fit(x_train, y_train)<br>\n",
    "  knn.predict(x_test)<br>\n",
    "  knn.score(x_test,y_test)<br>\n",
    "  * 하이퍼 파라미터<br>\n",
    "    1) algorithm : 가장 가까운 이웃을 계산하는데 사용하는 알고리즘으로 auto 는 fit 메소드에서 전달된 값을 기반으로 가장 적합한 알고리즘을 결정하려고 시도하는 것 입니다. (그 외 ball_tree, kd_tree, brute)<br>\n",
    "    2) Leaf_size : ballTree 나 kd_tree에 전달하는 leaf의 크기로,  default 값은 30입니다.트리에서 몇 대 몇으로 나눠서 뻗어 나갈지를 나타내는 값으로 Leaf size가 너무 작으면, 가지 수가 너무 많아 짐에 따라 노이즈가 끼기 쉽고 속도가 느리다. Leaf size가 너무 크면, 너무 대충 분류해서 예측 성능이 낮아진다.<br>\n",
    "    3) metric: 거리 측정 방식을 변경하는 매개변수로 default 값은 minkowsi 입니다.<br>\n",
    "    4) metric_params: 메트릭 함수의 추가 키워드로 기본값은 None 이다<br>\n",
    "    5) n_jobs: 이웃을 검색하기 위해 실행하는 병렬 작업 수<br>\n",
    "    6) n_neighbors: 검색할 이웃의 수(default 5)<br>\n",
    "    7) p: minkowski 의 매개변수(1 : 맨허튼, 2: 유클리드, 2초과 : minkowski)<br>\n",
    "    8) Weights : 예측에 사용하는 가중치로 uniform 은 각 이웃에 동일한 가중치를 , ‘distance’는 가까운 이웃이 멀리 있는 이웃보다 더욱 큰 영향을 미친다<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 로지스틱 회귀(logistic regressor)\n",
    "- 회귀를 사용하여 데이터가 어떤 범주에 속할 확률을 0에서 1 사이의 값으로 예측하고 그 확률에 따라 가능성이 더 높은 범주에 속하는 것으로 분류해주는 지도 학습 알고리즘<br>\n",
    "- 로직<br>\n",
    "  1) 모든 속성(feature)들의 계수(coefficient)와 절편(intercept)을 0으로 초기화한다.<br>\n",
    "  2) 각 속성들의 값(value)에 계수(coefficient)를 곱해서 log-odds를 구한다.<br>\n",
    "  3) log-odds를 sigmoid 함수에 넣어서 [0,1] 범위의 확률을 구한다.<br>\n",
    "- 로그 손실(log loss) : 로지스틱 회귀에 대한 손실 함수<br>\n",
    "- 임계값(Classification Threshold) : 데이터가 클래스에 속할지 말지 결정할 확률 컷오프, 주로 0.5(default)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
